{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LabanPoseTransformation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skore11/Laban_Pose_Conditional_GAN/blob/main/LabanPoseTransformation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUbEATYXlEHP"
      },
      "source": [
        "!pip install aiohttp nest_asyncio tqdm c3d numpy scipy torch matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf84aVyp8M7K"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "#from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "from zipfile import ZipFile\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "#cuda = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vox5OcIbqJtF"
      },
      "source": [
        "# Given a 2D Matrix a, sort and compute the diffs of the rows.\n",
        "# Only keep the row if the diff is greater than the \n",
        "# tolerance\n",
        "# Returns the index array corresponding to the rows to keep\n",
        "def rough_unique(a, tol=2**13):\n",
        "    i = np.argsort(a, axis=0)[:,0]\n",
        "    d = np.append(tol*2, np.mean(abs(np.diff(a[i], axis=0)), axis=1))\n",
        "    return i[(d/a.shape[1])>tol]\n",
        "\n",
        "DATA_ZIP = \"./data.zip\" # where the data is downloaded to\n",
        "DATA_DIR = \"./data\" # where the data is unzipped to\n",
        "def get_data_zip(\n",
        "        url=\"https://cyprus-data.s3.us-east-2.amazonaws.com/data.zip\",\n",
        "        chunk_size=8192,\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Ensure that dataset is downloaded and unzipped\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(DATA_ZIP): # not already downloaded\n",
        "        filesize = int(requests.head(url).headers[\"Content-Length\"])\n",
        "        progress = tqdm(\n",
        "            unit=\"B\", \n",
        "            unit_scale=True, \n",
        "            unit_divisor=1024, \n",
        "            total=filesize, \n",
        "            desc=DATA_ZIP)\n",
        "        r = requests.get(url, stream=True)\n",
        "        with open(DATA_ZIP, 'wb') as fp:\n",
        "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "                wrote = fp.write(chunk)\n",
        "                progress.update(wrote)\n",
        "            progress.close()\n",
        "    if not os.path.isdir(DATA_DIR): # not already unzipped\n",
        "        with ZipFile(DATA_ZIP, 'r') as zp:\n",
        "            files = zp.namelist()\n",
        "            progress = tqdm(\n",
        "                total=len(files), \n",
        "                desc=\"Unzipping {}\".format(DATA_DIR))\n",
        "            for name in files:\n",
        "                zp.extract(name)\n",
        "                progress.update()\n",
        "            progress.close()\n",
        "    return\n",
        "\n",
        "def cyprus_dataset(toTensor):\n",
        "    \"\"\"\n",
        "    Loads our augmented version of the Cyprus Dataset,\n",
        "    returns two TensorDatasets, one for train and one for test\n",
        "    \"\"\"\n",
        "    MAX_ZEROS = 3 # max number of 0's a single pose can have\n",
        "    if not os.path.isdir(DATA_DIR):\n",
        "        raise Exception(\"{} does not exist, make sure the\\\n",
        "        data is downloaded and unzipped\".format(DATA_DIR))\n",
        "    get_data_zip() # Ensure data is downloaded\n",
        "    \n",
        "    # Get files from dataset\n",
        "    npys = []\n",
        "    for file in os.walk(DATA_DIR):\n",
        "        npys = file[2]\n",
        "        \n",
        "    # Load the data\n",
        "    labels_map = {\n",
        "        'afraid':  0,\n",
        "        'bored':   1,\n",
        "        'excited': 2,\n",
        "        'neutral': 3,\n",
        "        'relaxed': 4,\n",
        "    }\n",
        "    poses = np.array([])\n",
        "    labels = np.array([])\n",
        "    for npy in tqdm(npys, desc=\"Loading data\"):\n",
        "        data = np.load(os.path.join(DATA_DIR,npy)).astype('float32')\n",
        "        # Enforce MAX_ZEROS\n",
        "        valid_rows = np.sum(data == 0., axis=-1) < MAX_ZEROS\n",
        "        data = data[valid_rows]\n",
        "        # Remove similar poses\n",
        "        uis = rough_unique(data)\n",
        "        data = data[uis]\n",
        "            \n",
        "        # Augment data with random scale and translations, both \n",
        "        # together and separately\n",
        "        rand_scale = lambda: np.random.uniform(low=0.8,high=1.2,size=(data.shape[0],1))\n",
        "        rand_trans = lambda: np.hstack((\n",
        "            np.repeat(\n",
        "                np.random.uniform(low=-100.0,high=100.0,size=(data.shape[0],3)), \n",
        "            38, axis=1),\n",
        "            np.zeros((data.shape[0],17))))\n",
        "        scale = np.vstack([data*rand_scale() for i in range(16)])\n",
        "        trans = np.vstack([data+rand_trans() for i in range(16)])\n",
        "        both = np.vstack([(data*rand_scale())+rand_trans() for i in range(16)])\n",
        "        data = np.vstack([data,scale,trans,both])\n",
        "                \n",
        "        # Remove similar poses\n",
        "        uis = rough_unique(data)\n",
        "        data = data[uis]\n",
        "                \n",
        "        label = labels_map[npy.split(\"_\")[0]]\n",
        "                \n",
        "        if poses.any(): # there already is data, add to it\n",
        "            poses = np.vstack([poses,data])\n",
        "            # repeat label for all samples in file\n",
        "            labels = np.concatenate([\n",
        "                labels,\n",
        "                np.repeat(label,data.shape[0])], axis=None) \n",
        "        else: # first record, create arrays\n",
        "            poses = np.array(data)\n",
        "            labels = np.repeat(label,data.shape[0])     \n",
        "\n",
        "    # Enforce MAX_ZEROS\n",
        "    valid_rows = np.sum(poses == 0., axis=-1) < MAX_ZEROS\n",
        "    poses = poses[valid_rows]\n",
        "    labels = labels[valid_rows]\n",
        "        \n",
        "    # Remove similar poses\n",
        "    uis = rough_unique(poses,2**12)\n",
        "    poses = poses[uis]\n",
        "    labels = labels[uis]\n",
        "        \n",
        "    cutoff = int(poses.shape[0] * 0.8)\n",
        "    train_poses = toTensor(poses[:cutoff].astype('float32'))\n",
        "    train_labels = toTensor(labels[:cutoff].astype('float32'))\n",
        "    test_poses = toTensor(poses[cutoff:].astype('float32'))\n",
        "    test_labels = toTensor(labels[cutoff:].astype('float32'))\n",
        "    return TensorDataset(train_poses, train_labels), TensorDataset(test_poses, test_labels)\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vKZob8N5GTS"
      },
      "source": [
        "N_POINTS = 38*3\n",
        "N_FEATURES = 17\n",
        "N_DATA = N_POINTS+N_FEATURES\n",
        "N_CLASSES = 5\n",
        "N_NOISE = 19\n",
        "\n",
        "def add_tensors(x,y):\n",
        "    \"\"\"\n",
        "    Add x and y, trimming or zero-padding y to match the \n",
        "    size of x. Ensures z is on the same device as x\n",
        "    \"\"\"\n",
        "    b,u,_ = x.size()\n",
        "    v = y.size()[1]\n",
        "    w = min(u,v)\n",
        "    z = torch.zeros(b,u,1)\n",
        "    z[:,:w] = y[:,:w]\n",
        "    if cuda:\n",
        "        z = z.cuda()\n",
        "    return x+z\n",
        "\n",
        "class ResConv(nn.Module):\n",
        "    \"\"\"\n",
        "    Residual Convolutional layer from Generative Tweening\n",
        "    https://arxiv.org/pdf/2005.08891.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch, out_ch, kernel_size, stride, padding, ratio):\n",
        "        super(ResConv, self).__init__()\n",
        "        self.root_ratio = torch.sqrt(torch.tensor(float(max(0,ratio))))\n",
        "        self.om_root_ratio = torch.sqrt(torch.tensor(float(max(0,1.0-ratio))))\n",
        "        \n",
        "        self.conv = nn.Conv1d(\n",
        "            in_ch, out_ch, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.affine = nn.BatchNorm1d(out_ch, affine=True)\n",
        "        self.prelu = nn.PReLU(out_ch)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x_prime = self.conv(x)\n",
        "        prelu_affine = self.prelu(self.affine(x_prime))\n",
        "        res_x = add_tensors(prelu_affine, self.om_root_ratio * x)\n",
        "        y = add_tensors(self.root_ratio*res_x, self.om_root_ratio * x)\n",
        "        return y\n",
        "\n",
        "class ResConvT(ResConv):\n",
        "    \"\"\"\n",
        "    Transpose Residual Convolutional layer\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch, out_ch, kernel_size, stride, padding, ratio):\n",
        "        super(ResConvT, self).__init__(in_ch,out_ch,kernel_size,stride,padding,ratio)\n",
        "        self.conv = nn.ConvTranspose1d(\n",
        "            in_ch, out_ch, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"        \n",
        "    Similar to Generator and Discriminator from Generative Tweening\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.label_embedding = nn.Embedding(N_CLASSES, N_CLASSES)\n",
        "        self.model = nn.Sequential(\n",
        "            # Encoder\n",
        "            ResConv(N_DATA+N_NOISE+N_CLASSES, 256,3,2,1,1/1),\n",
        "            ResConv(256,512,3,2,1,1/2),\n",
        "            ResConv(512,768,3,2,1,1/3),\n",
        "            ResConv(768,1024,3,2,1,1/4),\n",
        "            ResConv(1024,1536,3,2,1,1/5),\n",
        "            ResConv(1536,2048,3,2,1,1/6),\n",
        "            # Decoder\n",
        "            ResConv(2048,1024,1,1,0,1/1),\n",
        "            ResConv(1024,1024,3,1,1,1/3),\n",
        "            ResConvT(1024,1024,3,2,1,1/3),\n",
        "            ResConv(1024,512,3,1,1,1/9),\n",
        "            ResConvT(512,512,3,2,1,1/9),\n",
        "            ResConv(512,256,3,1,1,1/18),\n",
        "            ResConvT(256,256,3,2,1,1/18),\n",
        "            ResConv(256,N_POINTS,3,1,1,1/28),\n",
        "        )\n",
        "        \n",
        "    def forward(self, pose, label, noise):\n",
        "        x = torch.cat((pose, self.label_embedding(label), noise), -1).unsqueeze(2)\n",
        "        y = self.model(x)\n",
        "        return y\n",
        "        \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            ResConv(N_POINTS,512,3,2,1,1/1),\n",
        "            ResConv(512,512,3,2,1,1/2),\n",
        "            ResConvT(512,512,3,2,1,1/3),\n",
        "            ResConv(512,512,3,2,1,1/4),\n",
        "            ResConvT(512,1024,3,2,1,1/5),\n",
        "            ResConv(1024,1024,3,2,1,1/6),\n",
        "            nn.Conv1d(1024,N_CLASSES,kernel_size=1,stride=1,padding=0),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        y = self.model(x)\n",
        "        return y\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvnhRtL95GTS"
      },
      "source": [
        "# For general setup and training approach:\n",
        "#   https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/cgan/cgan.py\n",
        "    \n",
        "# Training inits\n",
        "batch_size = int(2**7)\n",
        "epochs = 200\n",
        "lr = 0.00001\n",
        "b1 = 0.5\n",
        "b2 = 0.999\n",
        "\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "adversarial_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "FloatTensor = torch.FloatTensor\n",
        "LongTensor = torch.LongTensor\n",
        "\n",
        "# If GPU available, init for cuda\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "    \n",
        "    FloatTensor = torch.cuda.FloatTensor\n",
        "    LongTensor = torch.cuda.LongTensor\n",
        "\n",
        "# Create optimizers after moving model to GPU\n",
        "#opt_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "#opt_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
        "opt_G = torch.optim.RMSprop(generator.parameters(), lr=lr)\n",
        "opt_D = torch.optim.RMSprop(discriminator.parameters(), lr=lr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQTo0eO15GTT"
      },
      "source": [
        "# Load data, display pie chart to show split\n",
        "train, test = cyprus_dataset(FloatTensor)\n",
        "    \n",
        "# Count occurences of each label\n",
        "count = {}\n",
        "for _, label in tqdm(train, desc=\"Analyzing data\"):\n",
        "    count[int(label)] = count.get(int(label), 0) + 1\n",
        "\n",
        "total = len(train)\n",
        "print('Total Frames: {:,}'.format(total))\n",
        "\n",
        "# Create pie chart to display the makeup of the dataset\n",
        "pie_labels = ['afraid','bored','excited','neutral','relaxed']\n",
        "pcts = [count[k] / total for k in sorted(count.keys())]\n",
        "plt.pie(\n",
        "    pcts, \n",
        "    labels=[pie_labels[k] + \" {:.2f}%\".format(pcts[k]*100) for k in sorted(count.keys())], \n",
        "    normalize=False)\n",
        "plt.show()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO8t8Dk_5GTT"
      },
      "source": [
        "dl = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "print(\"Training started: {:,} total poses, batch size {:,}\".format(len(train), batch_size))\n",
        "op = tqdm(range(epochs), position=1, desc=\"Epoch\")\n",
        "break_early = False\n",
        "\n",
        "g_losses = np.array([])\n",
        "d_losses = np.array([])\n",
        "\n",
        "for epoch in op:\n",
        "    ip = tqdm(\n",
        "        enumerate(dl), \n",
        "        position=2, \n",
        "        total=int(len(train)/batch_size)+1,\n",
        "        desc=\"[G loss: ???] [D loss: ???]\",\n",
        "        leave=False)\n",
        "    \n",
        "    for i, (data, labels) in ip:        \n",
        "        # Train generator\n",
        "        opt_G.zero_grad()\n",
        "        noise = FloatTensor(np.random.normal(0, 1, (data.shape[0], N_NOISE)))\n",
        "        gen_labels = labels[torch.randperm(data.shape[0])].long()\n",
        "        gen_output = generator(data, gen_labels, noise)\n",
        "        \n",
        "        # How well are we fooling the discriminator \n",
        "        # (matching the desired label)?\n",
        "        cls = discriminator(gen_output).squeeze(2)\n",
        "        g_loss = adversarial_loss(cls, gen_labels)\n",
        "        g_loss.backward()\n",
        "        opt_G.step()\n",
        "        \n",
        "        # Train Discriminator\n",
        "        opt_D.zero_grad()\n",
        "        \n",
        "        # How well can the discriminator label real poses?\n",
        "        real_cls = discriminator(data[:,:N_POINTS].unsqueeze(2)).squeeze(2)\n",
        "        d_real_loss = adversarial_loss(real_cls, labels.long())\n",
        "        \n",
        "        # Can the discriminator detect the generated poses?\n",
        "        gen_cls = discriminator(gen_output.detach()).squeeze(2)\n",
        "        d_gen_loss = adversarial_loss(gen_cls, labels.long())\n",
        "        \n",
        "        d_loss = (d_real_loss + d_gen_loss) / 2\n",
        "        d_loss.backward()\n",
        "        opt_D.step()     \n",
        "        \n",
        "        # Update progress bar\n",
        "        ip.set_description(\n",
        "            desc=\"[G loss: %f] [D loss: %f]\"\n",
        "                % (g_loss.item(), d_loss.item())\n",
        "        )\n",
        "        \n",
        "        # Track losses\n",
        "        g_losses = np.append(g_losses, g_loss.item())\n",
        "        d_losses = np.append(d_losses, d_loss.item())\n",
        "        \n",
        "        # Break early on low generator loss\n",
        "        if g_loss.item() < 0.001:\n",
        "            break_early = True\n",
        "            break\n",
        "\n",
        "    ip.close()\n",
        "    \n",
        "    if break_early:\n",
        "        break\n",
        "    \n",
        "    torch.save(generator, \"generator_checkpoint.torch\")\n",
        "    torch.save(discriminator, \"discriminator_checkpoint.torch\")\n",
        "    \n",
        "torch.save(generator, \"generator_final.torch\")\n",
        "torch.save(discriminator, \"discriminator_final.torch\")\n",
        "print(\"Saved models!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKuMO6vp5GTT"
      },
      "source": [
        "# TODO: display poses\n",
        "# TODO: Play with losses + optimizers\n",
        "# TODO: speed up training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmwHxKiP5GTT"
      },
      "source": [
        "xs = np.arange(g_losses.shape[0])\n",
        "plt.plot(xs, g_losses, label=\"G Losses\")\n",
        "plt.plot(xs, d_losses, label=\"D Losses\")\n",
        "plt.xlabel(\"Training step (Batch)\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNYl0ol45GTT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}